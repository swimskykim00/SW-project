{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1Q440bZK4gjwxikDrHc1XBiEhiAwH6wPG",
      "authorship_tag": "ABX9TyN1SedbEdqA/Dl2BlPUb7uS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swimskykim00/SW-project/blob/main/%EA%B0%9C%EC%9D%B8%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B82(Mvtec).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ICb2SgxgfHy",
        "outputId": "0eeafeff-c446-4a9f-9e46-465339188b8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "!xz -d /content/drive/MyDrive/SW사업/carpet.tar.xz"
      ],
      "metadata": {
        "id": "vebyxWxUitHH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4IR4JKCEiquM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tar xvf /content/drive/MyDrive/SW사업/carpet.tar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6lTpllFiSCa",
        "outputId": "a405eebc-c6f9-4888-d30d-6e9eae42eae9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "carpet/\n",
            "carpet/ground_truth/\n",
            "carpet/ground_truth/color/\n",
            "carpet/ground_truth/color/016_mask.png\n",
            "carpet/ground_truth/color/017_mask.png\n",
            "carpet/ground_truth/color/018_mask.png\n",
            "carpet/ground_truth/color/000_mask.png\n",
            "carpet/ground_truth/color/001_mask.png\n",
            "carpet/ground_truth/color/002_mask.png\n",
            "carpet/ground_truth/color/003_mask.png\n",
            "carpet/ground_truth/color/004_mask.png\n",
            "carpet/ground_truth/color/005_mask.png\n",
            "carpet/ground_truth/color/006_mask.png\n",
            "carpet/ground_truth/color/007_mask.png\n",
            "carpet/ground_truth/color/008_mask.png\n",
            "carpet/ground_truth/color/009_mask.png\n",
            "carpet/ground_truth/color/010_mask.png\n",
            "carpet/ground_truth/color/011_mask.png\n",
            "carpet/ground_truth/color/012_mask.png\n",
            "carpet/ground_truth/color/013_mask.png\n",
            "carpet/ground_truth/color/014_mask.png\n",
            "carpet/ground_truth/color/015_mask.png\n",
            "carpet/ground_truth/cut/\n",
            "carpet/ground_truth/cut/000_mask.png\n",
            "carpet/ground_truth/cut/001_mask.png\n",
            "carpet/ground_truth/cut/002_mask.png\n",
            "carpet/ground_truth/cut/003_mask.png\n",
            "carpet/ground_truth/cut/004_mask.png\n",
            "carpet/ground_truth/cut/005_mask.png\n",
            "carpet/ground_truth/cut/006_mask.png\n",
            "carpet/ground_truth/cut/007_mask.png\n",
            "carpet/ground_truth/cut/008_mask.png\n",
            "carpet/ground_truth/cut/009_mask.png\n",
            "carpet/ground_truth/cut/010_mask.png\n",
            "carpet/ground_truth/cut/011_mask.png\n",
            "carpet/ground_truth/cut/012_mask.png\n",
            "carpet/ground_truth/cut/013_mask.png\n",
            "carpet/ground_truth/cut/014_mask.png\n",
            "carpet/ground_truth/cut/015_mask.png\n",
            "carpet/ground_truth/cut/016_mask.png\n",
            "carpet/ground_truth/hole/\n",
            "carpet/ground_truth/hole/000_mask.png\n",
            "carpet/ground_truth/hole/001_mask.png\n",
            "carpet/ground_truth/hole/002_mask.png\n",
            "carpet/ground_truth/hole/003_mask.png\n",
            "carpet/ground_truth/hole/004_mask.png\n",
            "carpet/ground_truth/hole/005_mask.png\n",
            "carpet/ground_truth/hole/006_mask.png\n",
            "carpet/ground_truth/hole/007_mask.png\n",
            "carpet/ground_truth/hole/008_mask.png\n",
            "carpet/ground_truth/hole/009_mask.png\n",
            "carpet/ground_truth/hole/010_mask.png\n",
            "carpet/ground_truth/hole/011_mask.png\n",
            "carpet/ground_truth/hole/012_mask.png\n",
            "carpet/ground_truth/hole/013_mask.png\n",
            "carpet/ground_truth/hole/014_mask.png\n",
            "carpet/ground_truth/hole/015_mask.png\n",
            "carpet/ground_truth/hole/016_mask.png\n",
            "carpet/ground_truth/metal_contamination/\n",
            "carpet/ground_truth/metal_contamination/000_mask.png\n",
            "carpet/ground_truth/metal_contamination/001_mask.png\n",
            "carpet/ground_truth/metal_contamination/002_mask.png\n",
            "carpet/ground_truth/metal_contamination/003_mask.png\n",
            "carpet/ground_truth/metal_contamination/004_mask.png\n",
            "carpet/ground_truth/metal_contamination/005_mask.png\n",
            "carpet/ground_truth/metal_contamination/006_mask.png\n",
            "carpet/ground_truth/metal_contamination/007_mask.png\n",
            "carpet/ground_truth/metal_contamination/008_mask.png\n",
            "carpet/ground_truth/metal_contamination/009_mask.png\n",
            "carpet/ground_truth/metal_contamination/010_mask.png\n",
            "carpet/ground_truth/metal_contamination/011_mask.png\n",
            "carpet/ground_truth/metal_contamination/012_mask.png\n",
            "carpet/ground_truth/metal_contamination/013_mask.png\n",
            "carpet/ground_truth/metal_contamination/014_mask.png\n",
            "carpet/ground_truth/metal_contamination/015_mask.png\n",
            "carpet/ground_truth/metal_contamination/016_mask.png\n",
            "carpet/ground_truth/thread/\n",
            "carpet/ground_truth/thread/018_mask.png\n",
            "carpet/ground_truth/thread/000_mask.png\n",
            "carpet/ground_truth/thread/001_mask.png\n",
            "carpet/ground_truth/thread/002_mask.png\n",
            "carpet/ground_truth/thread/003_mask.png\n",
            "carpet/ground_truth/thread/004_mask.png\n",
            "carpet/ground_truth/thread/005_mask.png\n",
            "carpet/ground_truth/thread/006_mask.png\n",
            "carpet/ground_truth/thread/007_mask.png\n",
            "carpet/ground_truth/thread/008_mask.png\n",
            "carpet/ground_truth/thread/009_mask.png\n",
            "carpet/ground_truth/thread/010_mask.png\n",
            "carpet/ground_truth/thread/011_mask.png\n",
            "carpet/ground_truth/thread/012_mask.png\n",
            "carpet/ground_truth/thread/013_mask.png\n",
            "carpet/ground_truth/thread/014_mask.png\n",
            "carpet/ground_truth/thread/015_mask.png\n",
            "carpet/ground_truth/thread/016_mask.png\n",
            "carpet/ground_truth/thread/017_mask.png\n",
            "carpet/test/\n",
            "carpet/test/color/\n",
            "carpet/test/color/000.png\n",
            "carpet/test/color/001.png\n",
            "carpet/test/color/002.png\n",
            "carpet/test/color/003.png\n",
            "carpet/test/color/004.png\n",
            "carpet/test/color/005.png\n",
            "carpet/test/color/006.png\n",
            "carpet/test/color/007.png\n",
            "carpet/test/color/008.png\n",
            "carpet/test/color/009.png\n",
            "carpet/test/color/010.png\n",
            "carpet/test/color/011.png\n",
            "carpet/test/color/012.png\n",
            "carpet/test/color/013.png\n",
            "carpet/test/color/014.png\n",
            "carpet/test/color/015.png\n",
            "carpet/test/color/016.png\n",
            "carpet/test/color/017.png\n",
            "carpet/test/color/018.png\n",
            "carpet/test/cut/\n",
            "carpet/test/cut/000.png\n",
            "carpet/test/cut/001.png\n",
            "carpet/test/cut/002.png\n",
            "carpet/test/cut/003.png\n",
            "carpet/test/cut/004.png\n",
            "carpet/test/cut/005.png\n",
            "carpet/test/cut/006.png\n",
            "carpet/test/cut/007.png\n",
            "carpet/test/cut/008.png\n",
            "carpet/test/cut/009.png\n",
            "carpet/test/cut/010.png\n",
            "carpet/test/cut/011.png\n",
            "carpet/test/cut/012.png\n",
            "carpet/test/cut/013.png\n",
            "carpet/test/cut/014.png\n",
            "carpet/test/cut/015.png\n",
            "carpet/test/cut/016.png\n",
            "carpet/test/good/\n",
            "carpet/test/good/025.png\n",
            "carpet/test/good/026.png\n",
            "carpet/test/good/027.png\n",
            "carpet/test/good/000.png\n",
            "carpet/test/good/001.png\n",
            "carpet/test/good/002.png\n",
            "carpet/test/good/003.png\n",
            "carpet/test/good/004.png\n",
            "carpet/test/good/005.png\n",
            "carpet/test/good/006.png\n",
            "carpet/test/good/007.png\n",
            "carpet/test/good/008.png\n",
            "carpet/test/good/009.png\n",
            "carpet/test/good/010.png\n",
            "carpet/test/good/011.png\n",
            "carpet/test/good/012.png\n",
            "carpet/test/good/013.png\n",
            "carpet/test/good/014.png\n",
            "carpet/test/good/015.png\n",
            "carpet/test/good/016.png\n",
            "carpet/test/good/017.png\n",
            "carpet/test/good/018.png\n",
            "carpet/test/good/019.png\n",
            "carpet/test/good/020.png\n",
            "carpet/test/good/021.png\n",
            "carpet/test/good/022.png\n",
            "carpet/test/good/023.png\n",
            "carpet/test/good/024.png\n",
            "carpet/test/hole/\n",
            "carpet/test/hole/000.png\n",
            "carpet/test/hole/001.png\n",
            "carpet/test/hole/002.png\n",
            "carpet/test/hole/003.png\n",
            "carpet/test/hole/004.png\n",
            "carpet/test/hole/005.png\n",
            "carpet/test/hole/006.png\n",
            "carpet/test/hole/007.png\n",
            "carpet/test/hole/008.png\n",
            "carpet/test/hole/009.png\n",
            "carpet/test/hole/010.png\n",
            "carpet/test/hole/011.png\n",
            "carpet/test/hole/012.png\n",
            "carpet/test/hole/013.png\n",
            "carpet/test/hole/014.png\n",
            "carpet/test/hole/015.png\n",
            "carpet/test/hole/016.png\n",
            "carpet/test/metal_contamination/\n",
            "carpet/test/metal_contamination/000.png\n",
            "carpet/test/metal_contamination/001.png\n",
            "carpet/test/metal_contamination/002.png\n",
            "carpet/test/metal_contamination/003.png\n",
            "carpet/test/metal_contamination/004.png\n",
            "carpet/test/metal_contamination/005.png\n",
            "carpet/test/metal_contamination/006.png\n",
            "carpet/test/metal_contamination/007.png\n",
            "carpet/test/metal_contamination/008.png\n",
            "carpet/test/metal_contamination/009.png\n",
            "carpet/test/metal_contamination/010.png\n",
            "carpet/test/metal_contamination/011.png\n",
            "carpet/test/metal_contamination/012.png\n",
            "carpet/test/metal_contamination/013.png\n",
            "carpet/test/metal_contamination/014.png\n",
            "carpet/test/metal_contamination/015.png\n",
            "carpet/test/metal_contamination/016.png\n",
            "carpet/test/thread/\n",
            "carpet/test/thread/000.png\n",
            "carpet/test/thread/001.png\n",
            "carpet/test/thread/002.png\n",
            "carpet/test/thread/003.png\n",
            "carpet/test/thread/004.png\n",
            "carpet/test/thread/005.png\n",
            "carpet/test/thread/006.png\n",
            "carpet/test/thread/007.png\n",
            "carpet/test/thread/008.png\n",
            "carpet/test/thread/009.png\n",
            "carpet/test/thread/010.png\n",
            "carpet/test/thread/011.png\n",
            "carpet/test/thread/012.png\n",
            "carpet/test/thread/013.png\n",
            "carpet/test/thread/014.png\n",
            "carpet/test/thread/015.png\n",
            "carpet/test/thread/016.png\n",
            "carpet/test/thread/017.png\n",
            "carpet/test/thread/018.png\n",
            "carpet/train/\n",
            "carpet/train/good/\n",
            "carpet/train/good/000.png\n",
            "carpet/train/good/001.png\n",
            "carpet/train/good/002.png\n",
            "carpet/train/good/003.png\n",
            "carpet/train/good/004.png\n",
            "carpet/train/good/005.png\n",
            "carpet/train/good/006.png\n",
            "carpet/train/good/007.png\n",
            "carpet/train/good/008.png\n",
            "carpet/train/good/009.png\n",
            "carpet/train/good/010.png\n",
            "carpet/train/good/011.png\n",
            "carpet/train/good/012.png\n",
            "carpet/train/good/013.png\n",
            "carpet/train/good/014.png\n",
            "carpet/train/good/015.png\n",
            "carpet/train/good/016.png\n",
            "carpet/train/good/017.png\n",
            "carpet/train/good/018.png\n",
            "carpet/train/good/019.png\n",
            "carpet/train/good/020.png\n",
            "carpet/train/good/021.png\n",
            "carpet/train/good/022.png\n",
            "carpet/train/good/023.png\n",
            "carpet/train/good/024.png\n",
            "carpet/train/good/025.png\n",
            "carpet/train/good/026.png\n",
            "carpet/train/good/027.png\n",
            "carpet/train/good/028.png\n",
            "carpet/train/good/029.png\n",
            "carpet/train/good/030.png\n",
            "carpet/train/good/130.png\n",
            "carpet/train/good/131.png\n",
            "carpet/train/good/132.png\n",
            "carpet/train/good/133.png\n",
            "carpet/train/good/134.png\n",
            "carpet/train/good/135.png\n",
            "carpet/train/good/136.png\n",
            "carpet/train/good/137.png\n",
            "carpet/train/good/138.png\n",
            "carpet/train/good/139.png\n",
            "carpet/train/good/140.png\n",
            "carpet/train/good/141.png\n",
            "carpet/train/good/142.png\n",
            "carpet/train/good/143.png\n",
            "carpet/train/good/144.png\n",
            "carpet/train/good/145.png\n",
            "carpet/train/good/146.png\n",
            "carpet/train/good/147.png\n",
            "carpet/train/good/148.png\n",
            "carpet/train/good/149.png\n",
            "carpet/train/good/150.png\n",
            "carpet/train/good/151.png\n",
            "carpet/train/good/152.png\n",
            "carpet/train/good/153.png\n",
            "carpet/train/good/154.png\n",
            "carpet/train/good/155.png\n",
            "carpet/train/good/156.png\n",
            "carpet/train/good/157.png\n",
            "carpet/train/good/158.png\n",
            "carpet/train/good/159.png\n",
            "carpet/train/good/160.png\n",
            "carpet/train/good/161.png\n",
            "carpet/train/good/162.png\n",
            "carpet/train/good/163.png\n",
            "carpet/train/good/164.png\n",
            "carpet/train/good/165.png\n",
            "carpet/train/good/166.png\n",
            "carpet/train/good/167.png\n",
            "carpet/train/good/168.png\n",
            "carpet/train/good/169.png\n",
            "carpet/train/good/170.png\n",
            "carpet/train/good/171.png\n",
            "carpet/train/good/172.png\n",
            "carpet/train/good/173.png\n",
            "carpet/train/good/174.png\n",
            "carpet/train/good/175.png\n",
            "carpet/train/good/176.png\n",
            "carpet/train/good/177.png\n",
            "carpet/train/good/178.png\n",
            "carpet/train/good/179.png\n",
            "carpet/train/good/180.png\n",
            "carpet/train/good/181.png\n",
            "carpet/train/good/182.png\n",
            "carpet/train/good/183.png\n",
            "carpet/train/good/184.png\n",
            "carpet/train/good/185.png\n",
            "carpet/train/good/186.png\n",
            "carpet/train/good/187.png\n",
            "carpet/train/good/188.png\n",
            "carpet/train/good/189.png\n",
            "carpet/train/good/190.png\n",
            "carpet/train/good/191.png\n",
            "carpet/train/good/192.png\n",
            "carpet/train/good/193.png\n",
            "carpet/train/good/194.png\n",
            "carpet/train/good/195.png\n",
            "carpet/train/good/196.png\n",
            "carpet/train/good/197.png\n",
            "carpet/train/good/198.png\n",
            "carpet/train/good/199.png\n",
            "carpet/train/good/200.png\n",
            "carpet/train/good/201.png\n",
            "carpet/train/good/202.png\n",
            "carpet/train/good/203.png\n",
            "carpet/train/good/204.png\n",
            "carpet/train/good/205.png\n",
            "carpet/train/good/206.png\n",
            "carpet/train/good/207.png\n",
            "carpet/train/good/208.png\n",
            "carpet/train/good/209.png\n",
            "carpet/train/good/210.png\n",
            "carpet/train/good/211.png\n",
            "carpet/train/good/212.png\n",
            "carpet/train/good/213.png\n",
            "carpet/train/good/214.png\n",
            "carpet/train/good/215.png\n",
            "carpet/train/good/216.png\n",
            "carpet/train/good/217.png\n",
            "carpet/train/good/218.png\n",
            "carpet/train/good/219.png\n",
            "carpet/train/good/220.png\n",
            "carpet/train/good/221.png\n",
            "carpet/train/good/222.png\n",
            "carpet/train/good/223.png\n",
            "carpet/train/good/224.png\n",
            "carpet/train/good/225.png\n",
            "carpet/train/good/226.png\n",
            "carpet/train/good/227.png\n",
            "carpet/train/good/228.png\n",
            "carpet/train/good/229.png\n",
            "carpet/train/good/230.png\n",
            "carpet/train/good/231.png\n",
            "carpet/train/good/232.png\n",
            "carpet/train/good/233.png\n",
            "carpet/train/good/234.png\n",
            "carpet/train/good/235.png\n",
            "carpet/train/good/236.png\n",
            "carpet/train/good/237.png\n",
            "carpet/train/good/238.png\n",
            "carpet/train/good/239.png\n",
            "carpet/train/good/240.png\n",
            "carpet/train/good/241.png\n",
            "carpet/train/good/242.png\n",
            "carpet/train/good/243.png\n",
            "carpet/train/good/244.png\n",
            "carpet/train/good/245.png\n",
            "carpet/train/good/246.png\n",
            "carpet/train/good/247.png\n",
            "carpet/train/good/248.png\n",
            "carpet/train/good/249.png\n",
            "carpet/train/good/250.png\n",
            "carpet/train/good/251.png\n",
            "carpet/train/good/252.png\n",
            "carpet/train/good/253.png\n",
            "carpet/train/good/254.png\n",
            "carpet/train/good/255.png\n",
            "carpet/train/good/256.png\n",
            "carpet/train/good/257.png\n",
            "carpet/train/good/258.png\n",
            "carpet/train/good/259.png\n",
            "carpet/train/good/260.png\n",
            "carpet/train/good/261.png\n",
            "carpet/train/good/262.png\n",
            "carpet/train/good/263.png\n",
            "carpet/train/good/264.png\n",
            "carpet/train/good/266.png\n",
            "carpet/train/good/267.png\n",
            "carpet/train/good/268.png\n",
            "carpet/train/good/269.png\n",
            "carpet/train/good/270.png\n",
            "carpet/train/good/271.png\n",
            "carpet/train/good/272.png\n",
            "carpet/train/good/273.png\n",
            "carpet/train/good/274.png\n",
            "carpet/train/good/275.png\n",
            "carpet/train/good/276.png\n",
            "carpet/train/good/277.png\n",
            "carpet/train/good/278.png\n",
            "carpet/train/good/279.png\n",
            "carpet/train/good/032.png\n",
            "carpet/train/good/033.png\n",
            "carpet/train/good/034.png\n",
            "carpet/train/good/035.png\n",
            "carpet/train/good/036.png\n",
            "carpet/train/good/037.png\n",
            "carpet/train/good/038.png\n",
            "carpet/train/good/039.png\n",
            "carpet/train/good/040.png\n",
            "carpet/train/good/041.png\n",
            "carpet/train/good/042.png\n",
            "carpet/train/good/043.png\n",
            "carpet/train/good/044.png\n",
            "carpet/train/good/045.png\n",
            "carpet/train/good/046.png\n",
            "carpet/train/good/047.png\n",
            "carpet/train/good/048.png\n",
            "carpet/train/good/049.png\n",
            "carpet/train/good/050.png\n",
            "carpet/train/good/051.png\n",
            "carpet/train/good/052.png\n",
            "carpet/train/good/053.png\n",
            "carpet/train/good/054.png\n",
            "carpet/train/good/055.png\n",
            "carpet/train/good/056.png\n",
            "carpet/train/good/057.png\n",
            "carpet/train/good/058.png\n",
            "carpet/train/good/059.png\n",
            "carpet/train/good/060.png\n",
            "carpet/train/good/061.png\n",
            "carpet/train/good/062.png\n",
            "carpet/train/good/063.png\n",
            "carpet/train/good/064.png\n",
            "carpet/train/good/065.png\n",
            "carpet/train/good/066.png\n",
            "carpet/train/good/067.png\n",
            "carpet/train/good/068.png\n",
            "carpet/train/good/069.png\n",
            "carpet/train/good/070.png\n",
            "carpet/train/good/071.png\n",
            "carpet/train/good/072.png\n",
            "carpet/train/good/073.png\n",
            "carpet/train/good/074.png\n",
            "carpet/train/good/075.png\n",
            "carpet/train/good/076.png\n",
            "carpet/train/good/077.png\n",
            "carpet/train/good/078.png\n",
            "carpet/train/good/079.png\n",
            "carpet/train/good/080.png\n",
            "carpet/train/good/081.png\n",
            "carpet/train/good/082.png\n",
            "carpet/train/good/083.png\n",
            "carpet/train/good/084.png\n",
            "carpet/train/good/085.png\n",
            "carpet/train/good/086.png\n",
            "carpet/train/good/087.png\n",
            "carpet/train/good/088.png\n",
            "carpet/train/good/089.png\n",
            "carpet/train/good/090.png\n",
            "carpet/train/good/091.png\n",
            "carpet/train/good/092.png\n",
            "carpet/train/good/093.png\n",
            "carpet/train/good/094.png\n",
            "carpet/train/good/095.png\n",
            "carpet/train/good/096.png\n",
            "carpet/train/good/097.png\n",
            "carpet/train/good/098.png\n",
            "carpet/train/good/099.png\n",
            "carpet/train/good/100.png\n",
            "carpet/train/good/101.png\n",
            "carpet/train/good/102.png\n",
            "carpet/train/good/103.png\n",
            "carpet/train/good/104.png\n",
            "carpet/train/good/105.png\n",
            "carpet/train/good/106.png\n",
            "carpet/train/good/107.png\n",
            "carpet/train/good/108.png\n",
            "carpet/train/good/109.png\n",
            "carpet/train/good/110.png\n",
            "carpet/train/good/111.png\n",
            "carpet/train/good/112.png\n",
            "carpet/train/good/113.png\n",
            "carpet/train/good/114.png\n",
            "carpet/train/good/115.png\n",
            "carpet/train/good/116.png\n",
            "carpet/train/good/117.png\n",
            "carpet/train/good/118.png\n",
            "carpet/train/good/119.png\n",
            "carpet/train/good/120.png\n",
            "carpet/train/good/121.png\n",
            "carpet/train/good/122.png\n",
            "carpet/train/good/123.png\n",
            "carpet/train/good/124.png\n",
            "carpet/train/good/125.png\n",
            "carpet/train/good/126.png\n",
            "carpet/train/good/127.png\n",
            "carpet/train/good/128.png\n",
            "carpet/train/good/129.png\n",
            "carpet/train/good/265.png\n",
            "carpet/train/good/031.png\n",
            "carpet/readme.txt\n",
            "carpet/license.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "# 이거 폴더 안의 모든 거에 대한 경로가 다 담겨져있음 리스트형태로\n",
        "\n",
        "# ground_truth 파일 경로\n",
        "# data_dir_ground_color = glob.glob(\"/content/carpet/ground_truth/color/*\")\n",
        "# data_dir_ground_cut = glob.glob(\"/content/carpet/ground_truth/cut/*\")\n",
        "# data_dir_ground_hole = glob.glob(\"/content/carpet/ground_truth/hole/*\")\n",
        "# data_dir_ground_metal_contam = glob.glob(\"/content/carpet/ground_truth/metal_contamination/*\")\n",
        "# data_dir_ground_thread = glob.glob(\"/content/carpet/ground_truth/thread/*\")\n",
        "\n",
        "# test 파일 경로\n",
        "data_dir_test_color = glob.glob(\"/content/carpet/test/color/*\")\n",
        "data_dir_test_cut = glob.glob(\"/content/carpet/test/cut/*\")\n",
        "data_dir_test_good = glob.glob(\"/content/carpet/test/good/*\")\n",
        "data_dir_test_hole = glob.glob(\"/content/carpet/test/hole/*\")\n",
        "data_dir_test_metal_contam = glob.glob(\"/content/carpet/test/metal_contamination/*\")\n",
        "data_dir_test_thread = glob.glob(\"/content/carpet/test/thread/*\")\n",
        "\n",
        "# train 파일 경로\n",
        "data_dir_train_good = glob.glob(\"/content/carpet/train/good/*\")"
      ],
      "metadata": {
        "id": "3doNKwWKqQh8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from PIL import Image\n",
        "# img = Image.open(data_dir_test_color[12])\n",
        "# img\n",
        "# import numpy as np\n",
        "# np_image = np.array(img)\n",
        "# np_image.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3M4-dUEudP3",
        "outputId": "4b1a0bff-d3be-4830-d51c-32b56546a1ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1024, 1024, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Combine all the file paths in a list\n",
        "file_paths_train = data_dir_train_good\n",
        "list_file_path_test = [data_dir_test_color, data_dir_test_cut, data_dir_test_good,data_dir_test_hole,data_dir_test_metal_contam,data_dir_test_thread ]\n",
        "\n",
        "train_image_list = []\n",
        "test_color_image_list = []\n",
        "test_cut_image_list = []\n",
        "test_good_image_list =[]\n",
        "test_hole_image_list = []\n",
        "test_metal_contam_image_list = []\n",
        "test_thread_image_list = []\n",
        "\n",
        "all_list_for_test = [test_color_image_list, test_cut_image_list, test_good_image_list, test_hole_image_list, test_metal_contam_image_list, test_thread_image_list]\n",
        "\n",
        "for image in data_dir_train_good:\n",
        "    # Open the image using PIL\n",
        "    img = Image.open(image)\n",
        "\n",
        "    # Resize the image to (512, 512)\n",
        "    img = img.resize((512, 512))\n",
        "\n",
        "    # Convert the image to a NumPy array and scale pixel values to range 0-1\n",
        "    np_image = np.array(img) / 255.0\n",
        "\n",
        "    train_image_list.append(np_image)\n",
        "\n",
        "# Iterate over each class-specific list and file path list\n",
        "for class_list, file_paths in zip(all_list_for_test, list_file_path_test):\n",
        "    # Iterate over each file path in the current class\n",
        "    for file_path in file_paths:\n",
        "        # Open the image using PIL\n",
        "        img = Image.open(file_path)\n",
        "        # Resize the image to (512, 512)\n",
        "        img = img.resize((512, 512))\n",
        "        # Convert the image to a NumPy array\n",
        "        np_image = np.array(img) / 255.0\n",
        "\n",
        "        # Append the NumPy array to the current class-specific list\n",
        "        class_list.append(np_image)"
      ],
      "metadata": {
        "id": "xQOHj1FRq7f6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a list of dataframes and corresponding target labels\n",
        "dataframes = [test_color_image_list, test_cut_image_list, test_hole_image_list,\n",
        "              test_metal_contam_image_list, test_thread_image_list, test_good_image_list]\n",
        "\n",
        "target_labels = [1, 1, 1, 1, 1, 0]\n",
        "\n",
        "# Create dataframes and concatenate them\n",
        "dfs = [pd.DataFrame({'image': images, 'target': [target] * len(images)}) for images, target in zip(dataframes, target_labels)]\n",
        "df_test = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# Print the combined dataframe\n",
        "print(df_test)\n",
        "\n",
        "# Create a DataFrame for the train data\n",
        "df_train = pd.DataFrame({'image': train_image_list, 'target': [0] * len(train_image_list)})\n",
        "\n",
        "print(df_train)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLdBqbJu3EX0",
        "outputId": "ff6397e8-f811-486a-ee40-5cfb78ffc402"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 image  target\n",
            "0    [[[0.1607843137254902, 0.1568627450980392, 0.1...       1\n",
            "1    [[[0.2823529411764706, 0.2549019607843137, 0.2...       1\n",
            "2    [[[0.12549019607843137, 0.13333333333333333, 0...       1\n",
            "3    [[[0.16470588235294117, 0.15294117647058825, 0...       1\n",
            "4    [[[0.3137254901960784, 0.2784313725490196, 0.2...       1\n",
            "..                                                 ...     ...\n",
            "112  [[[0.2980392156862745, 0.2901960784313726, 0.2...       0\n",
            "113  [[[0.21176470588235294, 0.1803921568627451, 0....       0\n",
            "114  [[[0.25098039215686274, 0.24313725490196078, 0...       0\n",
            "115  [[[0.3058823529411765, 0.29411764705882354, 0....       0\n",
            "116  [[[0.21568627450980393, 0.1843137254901961, 0....       0\n",
            "\n",
            "[117 rows x 2 columns]\n",
            "                                                 image  target\n",
            "0    [[[0.22745098039215686, 0.20784313725490197, 0...       0\n",
            "1    [[[0.44313725490196076, 0.4549019607843137, 0....       0\n",
            "2    [[[0.2549019607843137, 0.23921568627450981, 0....       0\n",
            "3    [[[0.38823529411764707, 0.396078431372549, 0.4...       0\n",
            "4    [[[0.30980392156862746, 0.32941176470588235, 0...       0\n",
            "..                                                 ...     ...\n",
            "275  [[[0.2823529411764706, 0.27450980392156865, 0....       0\n",
            "276  [[[0.30196078431372547, 0.3058823529411765, 0....       0\n",
            "277  [[[0.3058823529411765, 0.3176470588235294, 0.3...       0\n",
            "278  [[[0.2901960784313726, 0.28627450980392155, 0....       0\n",
            "279  [[[0.37254901960784315, 0.3215686274509804, 0....       0\n",
            "\n",
            "[280 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df_test.copy()\n",
        "df2 = df_train.copy()"
      ],
      "metadata": {
        "id": "os7usfugEfzC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Save the dataframe to a CSV file\n",
        "# df.to_csv('/content/mvtec_carpet_final_df.csv', index=False)\n",
        "# import shutil\n",
        "# shutil.move('/content/mvtec_carpet_final_df.csv', '/content/drive/MyDrive/')"
      ],
      "metadata": {
        "id": "2BtFY4rlHJ_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train = df_train['image']\n",
        "y_train = df_train['target']\n",
        "X_test = df_test['image']\n",
        "y_test = df_test['target']\n",
        "\n",
        "# print(X_train)\n",
        "# print(y_train)\n",
        "# print(X_test)\n",
        "# print(y_test)\n",
        "\n",
        "print(type(X_train))\n",
        "print(type(X_test))\n",
        "\n",
        "\n",
        "# Split the test data into training  testing sets\n",
        "X_train_classify, X_test_classify, y_train_classify, y_test_classify = train_test_split(X_test, y_test, test_size=0.2, stratify=y_test, random_state = 1024)\n",
        "\n",
        "\n",
        "# change the series object into a tensor object so we can input it into a model\n",
        "X_train = np.array(X_train.tolist())\n",
        "X_test = np.array(X_test.tolist())\n",
        "y_train = np.array(y_train.tolist())\n",
        "y_test = np.array(y_test.tolist())\n",
        "\n",
        "X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
        "X_test = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
        "y_train = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
        "y_test = tf.convert_to_tensor(y_test, dtype=tf.float32)\n",
        "\n",
        "X_train_classify = np.array(X_train_classify.tolist())\n",
        "X_test_classify = np.array(X_test_classify.tolist())\n",
        "y_train_classify = np.array(y_train_classify.tolist())\n",
        "y_test_classify = np.array(y_test_classify.tolist())\n",
        "\n",
        "X_train_classify = tf.convert_to_tensor(X_train_classify, dtype=tf.float32)\n",
        "X_test_classify = tf.convert_to_tensor(X_test_classify, dtype=tf.float32)\n",
        "y_train_classify = tf.convert_to_tensor(y_train_classify, dtype=tf.float32)\n",
        "y_test_classify = tf.convert_to_tensor(y_test_classify, dtype=tf.float32)\n",
        "\n",
        "type(X_train)"
      ],
      "metadata": {
        "id": "kMvMdkGAO8XM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4460351e-503b-4f45-c899-4e1fd04d52f0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "<class 'pandas.core.series.Series'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.framework.ops.EagerTensor"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4B8MfzdF9al",
        "outputId": "4f76db35-04b2-4d34-c913-8f7f0a4c8d49"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(280, 512, 512, 3)\n",
            "(117, 512, 512, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "input_shape = (512, 512, 3)\n",
        "\n",
        "# Encoder\n",
        "encoder_input = tf.keras.Input(shape=input_shape)\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(encoder_input)\n",
        "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# Bottleneck layer\n",
        "encoded = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
        "\n",
        "# Decoder\n",
        "x = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "\n",
        "# Dropout layer to prevent overfitting\n",
        "x = layers.Dropout(0.2)(x)\n",
        "\n",
        "decoded = layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "# Autoencoder model\n",
        "autoencoder = models.Model(encoder_input, decoded)\n",
        "\n",
        "# Compile the model\n",
        "autoencoder.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "autoencoder.summary()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sWsuyTLjedxL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "728b6fed-c978-45fd-d80e-def1b296fd17"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 512, 512, 3)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 512, 512, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 256, 256, 32)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 256, 256, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 128, 128, 64)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 128, 128, 128)     73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 64, 64, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 64, 64, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 32, 32, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 32, 32, 512)       1180160   \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 32, 32, 256)       1179904   \n",
            "                                                                 \n",
            " up_sampling2d (UpSampling2D  (None, 64, 64, 256)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 64, 64, 128)       295040    \n",
            "                                                                 \n",
            " up_sampling2d_1 (UpSampling  (None, 128, 128, 128)    0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 128, 128, 64)      73792     \n",
            "                                                                 \n",
            " up_sampling2d_2 (UpSampling  (None, 256, 256, 64)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 256, 256, 32)      18464     \n",
            "                                                                 \n",
            " up_sampling2d_3 (UpSampling  (None, 512, 512, 32)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512, 512, 32)      0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 512, 512, 3)       867       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,136,643\n",
            "Trainable params: 3,136,643\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming X_train contains your training data\n",
        "autoencoder.fit(X_train, X_train, epochs=100, batch_size=32)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXB1BRbgYAli",
        "outputId": "5f734b9b-2eab-4d5d-ad43-687d3bb09887"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "9/9 [==============================] - 57s 3s/step - loss: 0.0395 - accuracy: 0.4458\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 9s 1s/step - loss: 0.0222 - accuracy: 0.4203\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 9s 997ms/step - loss: 0.0204 - accuracy: 0.4058\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 9s 996ms/step - loss: 0.0195 - accuracy: 0.3816\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 9s 1s/step - loss: 0.0192 - accuracy: 0.4276\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 9s 972ms/step - loss: 0.0189 - accuracy: 0.3824\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 9s 978ms/step - loss: 0.0188 - accuracy: 0.4075\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 9s 988ms/step - loss: 0.0186 - accuracy: 0.4114\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 9s 978ms/step - loss: 0.0185 - accuracy: 0.4253\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 9s 1s/step - loss: 0.0184 - accuracy: 0.4259\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 9s 1s/step - loss: 0.0183 - accuracy: 0.4232\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 9s 991ms/step - loss: 0.0185 - accuracy: 0.4349\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 9s 992ms/step - loss: 0.0187 - accuracy: 0.4369\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 9s 990ms/step - loss: 0.0184 - accuracy: 0.4296\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 9s 979ms/step - loss: 0.0183 - accuracy: 0.4388\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 9s 1s/step - loss: 0.0183 - accuracy: 0.4312\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 9s 985ms/step - loss: 0.0183 - accuracy: 0.4433\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 9s 974ms/step - loss: 0.0183 - accuracy: 0.4444\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 9s 986ms/step - loss: 0.0182 - accuracy: 0.4443\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 9s 999ms/step - loss: 0.0182 - accuracy: 0.4467\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 9s 967ms/step - loss: 0.0182 - accuracy: 0.4501\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 9s 977ms/step - loss: 0.0182 - accuracy: 0.4509\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 9s 986ms/step - loss: 0.0181 - accuracy: 0.4497\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 9s 969ms/step - loss: 0.0181 - accuracy: 0.4569\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 9s 971ms/step - loss: 0.0180 - accuracy: 0.4534\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 9s 989ms/step - loss: 0.0179 - accuracy: 0.4574\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 9s 962ms/step - loss: 0.0180 - accuracy: 0.4585\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 9s 1s/step - loss: 0.0178 - accuracy: 0.4583\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 9s 1s/step - loss: 0.0177 - accuracy: 0.4629\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 9s 967ms/step - loss: 0.0176 - accuracy: 0.4633\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 9s 1000ms/step - loss: 0.0181 - accuracy: 0.4598\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 9s 999ms/step - loss: 0.0177 - accuracy: 0.4640\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 9s 963ms/step - loss: 0.0176 - accuracy: 0.4655\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 9s 991ms/step - loss: 0.0175 - accuracy: 0.4674\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 9s 982ms/step - loss: 0.0173 - accuracy: 0.4767\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 9s 973ms/step - loss: 0.0167 - accuracy: 0.4843\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 9s 989ms/step - loss: 0.0158 - accuracy: 0.4838\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 9s 996ms/step - loss: 0.0153 - accuracy: 0.4761\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 9s 967ms/step - loss: 0.0148 - accuracy: 0.5048\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 9s 1s/step - loss: 0.0146 - accuracy: 0.5268\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 9s 987ms/step - loss: 0.0145 - accuracy: 0.5280\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 9s 978ms/step - loss: 0.0143 - accuracy: 0.5320\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 9s 988ms/step - loss: 0.0142 - accuracy: 0.5351\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 9s 997ms/step - loss: 0.0141 - accuracy: 0.5373\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 9s 998ms/step - loss: 0.0140 - accuracy: 0.5391\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 9s 1s/step - loss: 0.0140 - accuracy: 0.5438\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 9s 983ms/step - loss: 0.0138 - accuracy: 0.5428\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 9s 1s/step - loss: 0.0137 - accuracy: 0.5447\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 9s 1s/step - loss: 0.0136 - accuracy: 0.5473\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 9s 974ms/step - loss: 0.0134 - accuracy: 0.5479\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 9s 995ms/step - loss: 0.0132 - accuracy: 0.5494\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 9s 1s/step - loss: 0.0124 - accuracy: 0.5510\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 9s 984ms/step - loss: 0.0139 - accuracy: 0.4934\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 9s 992ms/step - loss: 0.0125 - accuracy: 0.5059\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 9s 997ms/step - loss: 0.0108 - accuracy: 0.5798\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 9s 971ms/step - loss: 0.0103 - accuracy: 0.5495\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 9s 994ms/step - loss: 0.0099 - accuracy: 0.5487\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 9s 998ms/step - loss: 0.0095 - accuracy: 0.5663\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 9s 1s/step - loss: 0.0094 - accuracy: 0.5839\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 9s 1s/step - loss: 0.0091 - accuracy: 0.5847\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 9s 995ms/step - loss: 0.0088 - accuracy: 0.5689\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 9s 1s/step - loss: 0.0120 - accuracy: 0.5542\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 9s 1s/step - loss: 0.0116 - accuracy: 0.5605\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 9s 988ms/step - loss: 0.0108 - accuracy: 0.5904\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 9s 968ms/step - loss: 0.0104 - accuracy: 0.5992\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 9s 1s/step - loss: 0.0101 - accuracy: 0.6068\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 9s 1s/step - loss: 0.0099 - accuracy: 0.5981\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 9s 972ms/step - loss: 0.0097 - accuracy: 0.6055\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 9s 992ms/step - loss: 0.0096 - accuracy: 0.6047\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 9s 974ms/step - loss: 0.0093 - accuracy: 0.6065\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 9s 967ms/step - loss: 0.0091 - accuracy: 0.6049\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 9s 1s/step - loss: 0.0089 - accuracy: 0.6133\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 9s 995ms/step - loss: 0.0094 - accuracy: 0.6158\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 9s 992ms/step - loss: 0.0090 - accuracy: 0.6275\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 9s 1s/step - loss: 0.0088 - accuracy: 0.6026\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 9s 995ms/step - loss: 0.0086 - accuracy: 0.6079\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 9s 971ms/step - loss: 0.0091 - accuracy: 0.6176\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 9s 988ms/step - loss: 0.0090 - accuracy: 0.6286\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 9s 975ms/step - loss: 0.0086 - accuracy: 0.6193\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 9s 963ms/step - loss: 0.0085 - accuracy: 0.6170\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 9s 987ms/step - loss: 0.0083 - accuracy: 0.6155\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 9s 980ms/step - loss: 0.0083 - accuracy: 0.6260\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 9s 985ms/step - loss: 0.0082 - accuracy: 0.6215\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 9s 1s/step - loss: 0.0081 - accuracy: 0.6212\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 9s 971ms/step - loss: 0.0080 - accuracy: 0.6158\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 9s 974ms/step - loss: 0.0080 - accuracy: 0.6195\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 9s 1s/step - loss: 0.0078 - accuracy: 0.6183\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 9s 982ms/step - loss: 0.0084 - accuracy: 0.6233\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 9s 984ms/step - loss: 0.0083 - accuracy: 0.6365\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 9s 986ms/step - loss: 0.0080 - accuracy: 0.6219\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 9s 977ms/step - loss: 0.0078 - accuracy: 0.6171\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 9s 991ms/step - loss: 0.0077 - accuracy: 0.6210\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 9s 1s/step - loss: 0.0076 - accuracy: 0.6225\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 9s 985ms/step - loss: 0.0076 - accuracy: 0.6292\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 9s 974ms/step - loss: 0.0075 - accuracy: 0.6213\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 9s 985ms/step - loss: 0.0074 - accuracy: 0.6225\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 9s 977ms/step - loss: 0.0074 - accuracy: 0.6245\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 9s 1s/step - loss: 0.0074 - accuracy: 0.6281\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 9s 1s/step - loss: 0.0073 - accuracy: 0.6258\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 9s 968ms/step - loss: 0.0072 - accuracy: 0.6243\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x79e9e5d83d60>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Train the Autoencoder (you've already done this)\n",
        "# autoencoder.fit(X_train, X_train, epochs=100, batch_size=32)\n",
        "\n",
        "# Step 2: Extract the Encoder\n",
        "# Define the encoder model\n",
        "encoder_model = models.Model(inputs=autoencoder.input, outputs=autoencoder.get_layer('conv2d_4').output)\n",
        "\n",
        "# Print the encoder model summary\n",
        "encoder_model.summary()\n",
        "\n",
        "\n",
        "# Step 3: Create the Classifier\n",
        "classifier_input = layers.Input(shape=(32, 32, 512))  # Set the correct input shape to match the output shape of the encoder\n",
        "x = layers.Flatten()(classifier_input)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "classifier_output = layers.Dense(1, activation='sigmoid')(x)\n",
        "classifier_model = models.Model(inputs=classifier_input, outputs=classifier_output)  # Use classifier_input as the input to the classifier model\n",
        "classifier_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "classifier_model.summary()\n",
        "\n",
        "\n",
        "\n",
        "# Apply the encoder to get the lower-dimensional representations (encoded images)\n",
        "encoded_images_training = encoder_model.predict(X_train_classify)\n",
        "encoded_images_test = encoder_model.predict(X_test_classify)\n",
        "\n",
        "# Train the classifier using the encoded images and corresponding labels\n",
        "classifier_model.fit(encoded_images_training, y_train_classify, epochs=100, batch_size=32)\n",
        "\n",
        "# Step 5: Evaluate the Classifier with a completely data\n",
        "loss, accuracy = classifier_model.evaluate(encoded_images_test, y_test_classify)\n",
        "print(f\"Test Loss: {loss}\")\n",
        "print(f\"Test Accuracy: {accuracy}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejMc1sT3d7US",
        "outputId": "8a22e247-b3be-42b5-9ae6-1ae80c0edaf4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 512, 512, 3)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 512, 512, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 256, 256, 32)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 256, 256, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 128, 128, 64)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 128, 128, 128)     73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 64, 64, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 64, 64, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 32, 32, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 32, 32, 512)       1180160   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,568,576\n",
            "Trainable params: 1,568,576\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 32, 32, 512)]     0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 524288)            0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                33554496  \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 33,554,561\n",
            "Trainable params: 33,554,561\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "3/3 [==============================] - 3s 1s/step\n",
            "1/1 [==============================] - 1s 510ms/step\n",
            "Epoch 1/100\n",
            "3/3 [==============================] - 1s 46ms/step - loss: 2.1960 - accuracy: 0.7634\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.5355 - accuracy: 0.6559\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.4902 - accuracy: 0.7527\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.4964 - accuracy: 0.7742\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.5685 - accuracy: 0.6667\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.2983 - accuracy: 0.8817\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.2648 - accuracy: 0.8495\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.2957 - accuracy: 0.8710\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.2066 - accuracy: 0.8817\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.2107 - accuracy: 0.9032\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 0.1631 - accuracy: 0.9785\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 0.1199 - accuracy: 0.9785\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.1063 - accuracy: 0.9785\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.1009 - accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.0861 - accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.0760 - accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.0731 - accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.0622 - accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.0624 - accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 0.0531 - accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 0.0519 - accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 0.0475 - accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.0456 - accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.0403 - accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 0.0376 - accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0361 - accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.0341 - accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.0309 - accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.0303 - accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.0280 - accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0264 - accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0256 - accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.0238 - accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.0226 - accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.0218 - accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.0211 - accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 62ms/step - loss: 0.0199 - accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.0185 - accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 0.0181 - accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0171 - accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.0163 - accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.0159 - accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0151 - accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0145 - accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0139 - accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.0135 - accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 64ms/step - loss: 0.0130 - accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.0126 - accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.0120 - accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 67ms/step - loss: 0.0116 - accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.0111 - accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 63ms/step - loss: 0.0108 - accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 69ms/step - loss: 0.0104 - accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 65ms/step - loss: 0.0102 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 74ms/step - loss: 0.0098 - accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.0094 - accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 63ms/step - loss: 0.0093 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 66ms/step - loss: 0.0089 - accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 80ms/step - loss: 0.0085 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 73ms/step - loss: 0.0084 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 59ms/step - loss: 0.0082 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 67ms/step - loss: 0.0078 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 66ms/step - loss: 0.0076 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 74ms/step - loss: 0.0073 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 0.0071 - accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 68ms/step - loss: 0.0070 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 0.0067 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.0065 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.0064 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.0062 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.0060 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0059 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.0057 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.0056 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.0054 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 0.0053 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.0052 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 0s 63ms/step - loss: 0.0050 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0049 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.0048 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 0.0045 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0045 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.0043 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.0041 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.3132 - accuracy: 0.7917\n",
            "Test Loss: 0.31321313977241516\n",
            "Test Accuracy: 0.7916666865348816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Assuming X_test contains your test data\n",
        "# loss = autoencoder.evaluate(X_test, X_test)\n",
        "\n",
        "# print(f\"Test Loss: {loss}\")\n",
        "# # Assuming X_test contains your test data\n",
        "# reconstructions = autoencoder.predict(X_test)\n",
        "# print(X_test)\n",
        "# mse = np.mean(np.square(X_test - reconstructions))\n",
        "\n",
        "# print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "\n",
        "# from keras import metrics\n",
        "\n",
        "# loss, accuracy = autoencoder.evaluate(X_test, X_test)\n",
        "# print(f\"Test Loss: {loss}\")\n",
        "# print(f\"Test Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uco3V93aQn5",
        "outputId": "4dca6a62-37ee-4b43-c818-a4381bc85c7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 6s 2s/step - loss: 0.6211 - accuracy: 0.8090\n",
            "Test Loss: [0.6210716962814331, 0.8089950680732727]\n",
            "4/4 [==============================] - 1s 140ms/step\n",
            "Mean Squared Error (MSE): 0.003011921187862754\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 0.6211 - accuracy: 0.8090\n",
            "Test Loss: 0.6210716962814331\n",
            "Test Accuracy: 0.8089950680732727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r-Pg3vUeeAD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_classify_all.fit(X_train,y_train,validation_data=(X_test,y_test), epochs=100)"
      ],
      "metadata": {
        "id": "MUI9aGCa7eTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이번엔 그냥 정상 비정상으로만 분류하는거 도전해보기\n",
        "simple_df = df.copy()\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Replace non-zero values in the 'target' column with 1\n",
        "simple_df.loc[simple_df['target'] != 0, 'target'] = 1\n",
        "\n",
        "# Print the updated DataFrame\n",
        "simple_df['target'].value_counts()"
      ],
      "metadata": {
        "id": "oiZ_LxSj86NA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32500988-780c-4b35-8ae0-b6c6152842a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    308\n",
              "1     89\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X1_train, X1_test, y1_train, y1_test = train_test_split(simple_df['image'], simple_df['target'], test_size=0.2, stratify=simple_df['target'])"
      ],
      "metadata": {
        "id": "V5p45Xwyhxj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJyK6Do0laqO",
        "outputId": "7ce263ae-0529-4423-cb5d-82005e9012f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    246\n",
              "1     71\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X1_train = X1_train.to_numpy()\n",
        "X1_test = X1_test.to_numpy()\n",
        "y1_train = y1_train.to_numpy()\n",
        "y1_test = y1_test.to_numpy()\n",
        "\n",
        "print(type(X1_train))\n",
        "\n",
        "X1_train = np.array(X1_train.tolist())\n",
        "X1_test = np.array(X1_test.tolist())\n",
        "y1_train = np.array(y1_train.tolist())\n",
        "y1_test = np.array(y1_test.tolist())\n",
        "\n",
        "print(type(X1_train))\n",
        "\n",
        "X1_train = tf.convert_to_tensor(X1_train, dtype=tf.float32)\n",
        "X1_test = tf.convert_to_tensor(X1_test, dtype=tf.float32)\n",
        "y1_train = tf.convert_to_tensor(y1_train, dtype=tf.float32)\n",
        "y1_test = tf.convert_to_tensor(y1_test, dtype=tf.float32)\n",
        "\n",
        "print(type(X1_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Hkd1BGYj04k",
        "outputId": "d7fd45d6-93c4-49bf-c45c-b45fa5c6d712"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow.keras import layers, models, callbacks\n",
        "\n",
        "# # Define the model\n",
        "# model = models.Sequential()\n",
        "\n",
        "# # Convolutional layers\n",
        "# model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3), padding='same'))\n",
        "# model.add(layers.MaxPooling2D((2, 2),padding='same'))\n",
        "# model.add(layers.Dropout(0.2))  # Add Dropout with 20% rate\n",
        "\n",
        "# model.add(layers.Conv2D(64, (3, 3), activation='relu' , padding= 'same'))\n",
        "# model.add(layers.Dropout(0.2))  # Add Dropout with 20% rate\n",
        "\n",
        "# model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "# model.add(layers.Dropout(0.2))  # Add Dropout with 20% rate\n",
        "\n",
        "# model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
        "# model.add(layers.MaxPooling2D((2, 2)))\n",
        "# model.add(layers.Dropout(0.2))  # Add Dropout with 20% rate\n",
        "\n",
        "# model.add(layers.Conv2D(512, (3, 3), activation='relu'))  # New convolutional layer\n",
        "# model.add(layers.Dropout(0.2))  # Add Dropout with 20% rate\n",
        "\n",
        "# # Flatten the feature maps\n",
        "# model.add(layers.Flatten())\n",
        "\n",
        "# # Dense layers\n",
        "# model.add(layers.Dense(128, activation='relu'))\n",
        "# model.add(layers.Dropout(0.5))  # Add Dropout with 50% rate\n",
        "# model.add(layers.Dense(64, activation='relu'))\n",
        "# model.add(layers.Dropout(0.5))  # Add Dropout with 50% rate\n",
        "# model.add(layers.Dense(1, activation='sigmoid'))  # Sigmoid activation for binary classification\n",
        "\n",
        "# # Compile the model\n",
        "# model.compile(optimizer='adam',\n",
        "#               loss='binary_crossentropy',\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# # Print the model summary\n",
        "# model.summary()\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "\n",
        "# Define the model\n",
        "model = models.Sequential()\n",
        "\n",
        "# Convolutional layers\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n",
        "model.add(layers.Dropout(0.2))  # Add Dropout with 20% rate\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2), padding= 'same'))\n",
        "model.add(layers.Dropout(0.2))  # Add Dropout with 20% rate\n",
        "\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Flatten the feature maps\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# Dense layers\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))  # Sigmoid activation for binary classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XV6_1Eotvfbk",
        "outputId": "fa886e11-445f-40bf-80f5-791da04d491b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_20 (Conv2D)          (None, 254, 254, 32)      896       \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 254, 254, 32)      0         \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 252, 252, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (None, 126, 126, 64)     0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 126, 126, 64)      0         \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 124, 124, 128)     73856     \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 62, 62, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 492032)            0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 64)                31490112  \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31,583,425\n",
            "Trainable params: 31,583,425\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train the model\n",
        "history = model.fit(X1_train, y1_train,\n",
        "                    validation_data=(X1_test, y1_test),\n",
        "                    epochs=200,\n",
        "                    )\n",
        "\n",
        "# Find the best model based on validation accuracy\n",
        "best_epoch = np.argmax(history.history['val_accuracy']) + 1\n",
        "best_validation_accuracy = max(history.history['val_accuracy'])\n",
        "print(f\"Best model is at epoch {best_epoch} with validation accuracy of {best_validation_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zw7ZazU-kSuQ",
        "outputId": "1ad4ed75-7679-4ad1-9f08-eba2b78d4189"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "10/10 [==============================] - 15s 866ms/step - loss: 5.4371 - accuracy: 0.6246 - val_loss: 0.5347 - val_accuracy: 0.7750\n",
            "Epoch 2/200\n",
            "10/10 [==============================] - 3s 298ms/step - loss: 0.5478 - accuracy: 0.7760 - val_loss: 0.5344 - val_accuracy: 0.7750\n",
            "Epoch 3/200\n",
            "10/10 [==============================] - 3s 295ms/step - loss: 0.5554 - accuracy: 0.7760 - val_loss: 0.6071 - val_accuracy: 0.7750\n",
            "Epoch 4/200\n",
            "10/10 [==============================] - 3s 293ms/step - loss: 0.5286 - accuracy: 0.7760 - val_loss: 0.5559 - val_accuracy: 0.7750\n",
            "Epoch 5/200\n",
            "10/10 [==============================] - 3s 294ms/step - loss: 0.5548 - accuracy: 0.7760 - val_loss: 0.5233 - val_accuracy: 0.7750\n",
            "Epoch 6/200\n",
            "10/10 [==============================] - 3s 299ms/step - loss: 0.5636 - accuracy: 0.7760 - val_loss: 0.6502 - val_accuracy: 0.7750\n",
            "Epoch 7/200\n",
            "10/10 [==============================] - 3s 298ms/step - loss: 0.5604 - accuracy: 0.7760 - val_loss: 0.5218 - val_accuracy: 0.7750\n",
            "Epoch 8/200\n",
            "10/10 [==============================] - 3s 300ms/step - loss: 0.5363 - accuracy: 0.7760 - val_loss: 0.5536 - val_accuracy: 0.7750\n",
            "Epoch 9/200\n",
            "10/10 [==============================] - 3s 296ms/step - loss: 0.5236 - accuracy: 0.7760 - val_loss: 0.5653 - val_accuracy: 0.7750\n",
            "Epoch 10/200\n",
            "10/10 [==============================] - 3s 298ms/step - loss: 0.5246 - accuracy: 0.7760 - val_loss: 0.5895 - val_accuracy: 0.7750\n",
            "Epoch 11/200\n",
            "10/10 [==============================] - 3s 302ms/step - loss: 0.5149 - accuracy: 0.7760 - val_loss: 0.5203 - val_accuracy: 0.7750\n",
            "Epoch 12/200\n",
            "10/10 [==============================] - 3s 300ms/step - loss: 0.5086 - accuracy: 0.7760 - val_loss: 0.5220 - val_accuracy: 0.7750\n",
            "Epoch 13/200\n",
            "10/10 [==============================] - 3s 297ms/step - loss: 0.5015 - accuracy: 0.7760 - val_loss: 0.4801 - val_accuracy: 0.7750\n",
            "Epoch 14/200\n",
            "10/10 [==============================] - 3s 298ms/step - loss: 0.4988 - accuracy: 0.7760 - val_loss: 0.4804 - val_accuracy: 0.7750\n",
            "Epoch 15/200\n",
            "10/10 [==============================] - 3s 303ms/step - loss: 0.4829 - accuracy: 0.7760 - val_loss: 0.4909 - val_accuracy: 0.7750\n",
            "Epoch 16/200\n",
            "10/10 [==============================] - 3s 300ms/step - loss: 0.5696 - accuracy: 0.7760 - val_loss: 0.6825 - val_accuracy: 0.7750\n",
            "Epoch 17/200\n",
            "10/10 [==============================] - 3s 295ms/step - loss: 0.6720 - accuracy: 0.7760 - val_loss: 0.6516 - val_accuracy: 0.7750\n",
            "Epoch 18/200\n",
            "10/10 [==============================] - 3s 296ms/step - loss: 0.5856 - accuracy: 0.7760 - val_loss: 0.5529 - val_accuracy: 0.7750\n",
            "Epoch 19/200\n",
            "10/10 [==============================] - 3s 295ms/step - loss: 0.5304 - accuracy: 0.7760 - val_loss: 0.5776 - val_accuracy: 0.7750\n",
            "Epoch 20/200\n",
            "10/10 [==============================] - 3s 301ms/step - loss: 0.4874 - accuracy: 0.7760 - val_loss: 0.4843 - val_accuracy: 0.7750\n",
            "Epoch 21/200\n",
            "10/10 [==============================] - 3s 295ms/step - loss: 0.4942 - accuracy: 0.7760 - val_loss: 0.4696 - val_accuracy: 0.7750\n",
            "Epoch 22/200\n",
            "10/10 [==============================] - 3s 296ms/step - loss: 0.5410 - accuracy: 0.7760 - val_loss: 0.5087 - val_accuracy: 0.7750\n",
            "Epoch 23/200\n",
            "10/10 [==============================] - 3s 293ms/step - loss: 0.5481 - accuracy: 0.7760 - val_loss: 0.5977 - val_accuracy: 0.7750\n",
            "Epoch 24/200\n",
            "10/10 [==============================] - 3s 296ms/step - loss: 0.5054 - accuracy: 0.7760 - val_loss: 0.5197 - val_accuracy: 0.7750\n",
            "Epoch 25/200\n",
            "10/10 [==============================] - 3s 301ms/step - loss: 0.4787 - accuracy: 0.7760 - val_loss: 0.4961 - val_accuracy: 0.7750\n",
            "Epoch 26/200\n",
            "10/10 [==============================] - 3s 295ms/step - loss: 0.4423 - accuracy: 0.7760 - val_loss: 0.4605 - val_accuracy: 0.7750\n",
            "Epoch 27/200\n",
            "10/10 [==============================] - 3s 294ms/step - loss: 0.4233 - accuracy: 0.7760 - val_loss: 0.4730 - val_accuracy: 0.7750\n",
            "Epoch 28/200\n",
            "10/10 [==============================] - 3s 296ms/step - loss: 0.4002 - accuracy: 0.7760 - val_loss: 0.4327 - val_accuracy: 0.7750\n",
            "Epoch 29/200\n",
            "10/10 [==============================] - 3s 301ms/step - loss: 0.4001 - accuracy: 0.7760 - val_loss: 0.5257 - val_accuracy: 0.7750\n",
            "Epoch 30/200\n",
            "10/10 [==============================] - 3s 297ms/step - loss: 0.3854 - accuracy: 0.7855 - val_loss: 0.4384 - val_accuracy: 0.7750\n",
            "Epoch 31/200\n",
            "10/10 [==============================] - 3s 298ms/step - loss: 0.3105 - accuracy: 0.8580 - val_loss: 0.4322 - val_accuracy: 0.7875\n",
            "Epoch 32/200\n",
            "10/10 [==============================] - 3s 299ms/step - loss: 0.2372 - accuracy: 0.9117 - val_loss: 0.4608 - val_accuracy: 0.7750\n",
            "Epoch 33/200\n",
            "10/10 [==============================] - 3s 302ms/step - loss: 0.1825 - accuracy: 0.9338 - val_loss: 0.4524 - val_accuracy: 0.7500\n",
            "Epoch 34/200\n",
            "10/10 [==============================] - 3s 308ms/step - loss: 0.1362 - accuracy: 0.9685 - val_loss: 0.5672 - val_accuracy: 0.7750\n",
            "Epoch 35/200\n",
            "10/10 [==============================] - 3s 303ms/step - loss: 0.0864 - accuracy: 0.9874 - val_loss: 0.5596 - val_accuracy: 0.7125\n",
            "Epoch 36/200\n",
            "10/10 [==============================] - 3s 302ms/step - loss: 0.0945 - accuracy: 0.9558 - val_loss: 0.7870 - val_accuracy: 0.7750\n",
            "Epoch 37/200\n",
            "10/10 [==============================] - 3s 300ms/step - loss: 0.0442 - accuracy: 0.9968 - val_loss: 0.7234 - val_accuracy: 0.7750\n",
            "Epoch 38/200\n",
            "10/10 [==============================] - 3s 307ms/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 0.7115 - val_accuracy: 0.6875\n",
            "Epoch 39/200\n",
            "10/10 [==============================] - 3s 304ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.9378 - val_accuracy: 0.7500\n",
            "Epoch 40/200\n",
            "10/10 [==============================] - 3s 303ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.0089 - val_accuracy: 0.7500\n",
            "Epoch 41/200\n",
            "10/10 [==============================] - 3s 305ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.9405 - val_accuracy: 0.6750\n",
            "Epoch 42/200\n",
            "10/10 [==============================] - 3s 311ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.0224 - val_accuracy: 0.7000\n",
            "Epoch 43/200\n",
            "10/10 [==============================] - 3s 329ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.1457 - val_accuracy: 0.7500\n",
            "Epoch 44/200\n",
            "10/10 [==============================] - 3s 301ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.0627 - val_accuracy: 0.6875\n",
            "Epoch 45/200\n",
            "10/10 [==============================] - 3s 305ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.0774 - val_accuracy: 0.6875\n",
            "Epoch 46/200\n",
            "10/10 [==============================] - 3s 304ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.1665 - val_accuracy: 0.7500\n",
            "Epoch 47/200\n",
            "10/10 [==============================] - 3s 308ms/step - loss: 9.7415e-04 - accuracy: 1.0000 - val_loss: 1.1116 - val_accuracy: 0.6875\n",
            "Epoch 48/200\n",
            "10/10 [==============================] - 3s 306ms/step - loss: 6.9736e-04 - accuracy: 1.0000 - val_loss: 1.1932 - val_accuracy: 0.7375\n",
            "Epoch 49/200\n",
            "10/10 [==============================] - 3s 305ms/step - loss: 6.2458e-04 - accuracy: 1.0000 - val_loss: 1.1630 - val_accuracy: 0.6875\n",
            "Epoch 50/200\n",
            "10/10 [==============================] - 3s 302ms/step - loss: 5.3509e-04 - accuracy: 1.0000 - val_loss: 1.1757 - val_accuracy: 0.6875\n",
            "Epoch 51/200\n",
            "10/10 [==============================] - 3s 302ms/step - loss: 5.8731e-04 - accuracy: 1.0000 - val_loss: 1.1827 - val_accuracy: 0.6875\n",
            "Epoch 52/200\n",
            "10/10 [==============================] - 3s 310ms/step - loss: 5.7461e-04 - accuracy: 1.0000 - val_loss: 1.2217 - val_accuracy: 0.7250\n",
            "Epoch 53/200\n",
            "10/10 [==============================] - 3s 308ms/step - loss: 4.8686e-04 - accuracy: 1.0000 - val_loss: 1.2017 - val_accuracy: 0.6875\n",
            "Epoch 54/200\n",
            "10/10 [==============================] - 3s 306ms/step - loss: 3.6316e-04 - accuracy: 1.0000 - val_loss: 1.2617 - val_accuracy: 0.7250\n",
            "Epoch 55/200\n",
            "10/10 [==============================] - 3s 306ms/step - loss: 4.2389e-04 - accuracy: 1.0000 - val_loss: 1.2246 - val_accuracy: 0.7000\n",
            "Epoch 56/200\n",
            "10/10 [==============================] - 3s 309ms/step - loss: 3.8279e-04 - accuracy: 1.0000 - val_loss: 1.2389 - val_accuracy: 0.7000\n",
            "Epoch 57/200\n",
            "10/10 [==============================] - 3s 307ms/step - loss: 2.9860e-04 - accuracy: 1.0000 - val_loss: 1.2738 - val_accuracy: 0.7125\n",
            "Epoch 58/200\n",
            "10/10 [==============================] - 3s 306ms/step - loss: 3.2248e-04 - accuracy: 1.0000 - val_loss: 1.2567 - val_accuracy: 0.7000\n",
            "Epoch 59/200\n",
            " 1/10 [==>...........................] - ETA: 2s - loss: 4.5316e-04 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-397d62a4a8fe>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history = model.fit(X1_train, y1_train,\n\u001b[0m\u001b[1;32m      3\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1689\u001b[0m                             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m                             \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1691\u001b[0;31m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1692\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1693\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \"\"\"\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m             \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1158\u001b[0m     \"\"\"\n\u001b[1;32m   1159\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1124\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1126\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1127\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BSCigCqonSQp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}